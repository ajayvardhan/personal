For my current job, one of the initial products was to let users teach whatever they want to Alexa. The users would go to any website, use the plugin to choose any text on the website, type a query they want to be related to this text and store it. Then they can ask Alexa this query that would retrieve the text they chose from the website dynamically and respond with it. Since I'm the only developer (apart from an architect) in the company, I developed the plugin and the segmentation of the webpage into text chunks for the user to choose. The webpage segmentation was a interesting problem to tackle.

The main constraint was to find all the text from any page and try to find chunks of text that would make sense together. I had to do several different approaches of DOM tree traversal and different thresholds for the grouping. After a couple of months of research and experimentations, I arrived at a solution where I traversed in reverse from the leaf nodes and added several conditions on which node I should stop that would form a meaningful text chunk. After the groups of tags are created, I edited the CSS of the page and added tiles for the groups of text. So when an user hovers over any group, it would focus that tile and blur out everything else on the page. Then the user can click on that tile and select the text to teach Alexa.

The main constraint in this project is that most of the websites don't follow any standards in the way they are coded. So I could not use any pattern based grouping. Some pages were based on JavaScript. Some had custom tags and unreadable text. So I had to develop a generic algorithm that would work for any website that would accommodate all these exceptions. I had to go through the code of many websites and many DOM trees to get to a point that would work in most of the websites. 

I'm proud of coming close to finishing this because I read a bunch of NLP papers and segmentation algorithms, but almost all of them worked on a specific pattern of websites or used computer vision to segment the pages. It was a great learning experience for me to do this using vanilla JS and on a Chrome plugin that could be used on any website. I got to master web scraping and working with different types of webpages all using JavaScript. I also mastered my tree and graph traversal algorithm skills that I could use in many places in the future.

Some of the tradeoffs I had to make were for pages that were nearly impossible to extract the text from. Some had too many advertisements. Some injected text from multiple JavaScripts. Some had flash rendering and iframe rendering. These pages were difficult to process so I had to omit them for this project due to time constraints. But if I had more time, I could have found a way to process them as well.
